{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6308dcc3f398bc1",
   "metadata": {},
   "source": [
    "# Chapter 3. 텐서 구조체\n",
    "\n",
    "- 딥러닝의 시작은 입력을 부동소수점으로 변환하는 것이고, 변환한 값을 담을 곳이 필요하다.\n",
    "- PyTorch에서는 텐서(Tensor)라는 자료구조를 사용한다.\n",
    "- 딥러닝에서의 텐서는 임의의 차원을 가진 벡터 또는 행렬의 일반화된 개념이다.\n",
    "- 텐서를 다차원 배열(multi-dimensional array)이라고 볼 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5573866f9e51a7",
   "metadata": {},
   "source": [
    "## 텐서 기초 조작"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-16T06:12:50.492999Z",
     "start_time": "2025-06-16T06:12:49.467249Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d135b798ca1e0d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:15:47.819009Z",
     "start_time": "2025-06-14T09:15:47.815151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크기가 3인 1차원 텐서에 값을 1로 채우기\n",
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39727b603daebf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:16:08.454877Z",
     "start_time": "2025-06-14T09:16:08.451660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# 인덱스로 접근 가능\n",
    "print(a[0], a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83d16e8de3f5686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:16:38.250796Z",
     "start_time": "2025-06-14T09:16:38.248140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python float로 변환\n",
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c67932365ad834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:16:59.031572Z",
     "start_time": "2025-06-14T09:16:59.025813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 인덱스에 값 할당\n",
    "a[2] = 2.\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c9db938a8332e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:02:59.594283Z",
     "start_time": "2025-06-14T10:02:59.589910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "torch.Size([3, 2])\n",
      "tensor(1.)\n",
      "tensor([4., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 2차원 텐서\n",
    "points = torch.tensor([[4.0, 1.0,], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points)\n",
    "print(points.shape)\n",
    "# 스칼라\n",
    "print(points[0, 1])\n",
    "# 1차원 텐서\n",
    "print(points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0db76f85903cf76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:05:58.806243Z",
     "start_time": "2025-06-14T10:05:58.802171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([5., 2.])\n",
      "tensor([[[4., 1.],\n",
      "         [5., 3.],\n",
      "         [2., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "### 텐서 인덱싱\n",
    "\n",
    "# 첫 번째 이후 모든 행에 대해, 모든 열이 선택됨\n",
    "print(points[1:])\n",
    "# 위와 같은 결과이지만, 열 표현을 명확히 하였음\n",
    "print(points[1:, :])\n",
    "# 첫 번째 이후 모든 행에 대해, 첫 번째 열만 선택됨\n",
    "print(points[1:, 0])\n",
    "# 길이가 1인 차원을 추가한다. Unsqueeze와 동일\n",
    "print(points[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0b71e2120d2e2",
   "metadata": {},
   "source": [
    "## 이름이 있는 텐서\n",
    "\n",
    "어느 차원에 어떤 데이터가 있는지 알 수 있도록 이름을 붙일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7860e2a8ae994b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:10:21.336142Z",
     "start_time": "2025-06-14T11:10:21.333511Z"
    }
   },
   "outputs": [],
   "source": [
    "### 예시 데이터 세팅\n",
    "img_t = torch.randn(3, 5, 5) # 3채널, 5x5 이미지\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722]) # RGB 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1f3d8e15152ca7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:10:43.436023Z",
     "start_time": "2025-06-14T11:10:43.433969Z"
    }
   },
   "outputs": [],
   "source": [
    "### 배치 예시 데이터 세팅\n",
    "batch_t = torch.randn(2, 3, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d2ffa3d493442fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:11:36.927255Z",
     "start_time": "2025-06-14T11:11:36.922011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RGB 채널은 img_t, batch_t 에서 항상 뒤에서 세 번째 차원에 위치한다. (-3 인덱스)\n",
    "img_graph_naive = img_t.mean(-3)\n",
    "batch_graph_naive = batch_t.mean(-3)\n",
    "img_graph_naive.shape, batch_graph_naive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e093e2852dff8f",
   "metadata": {},
   "source": [
    "`batch_t`의 경우, 배치 차원으로 인해 5x5 이미지가 2개가 있다. 따라서 shape은 (2, 5, 5)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97203da6675698",
   "metadata": {},
   "source": [
    "두 텐서의 Shape이 다르면 일반적으로는 연산이 불가능하다.\n",
    "\n",
    "하지만, Shape의 일부만 다른 특정 경우에는 PyTorch가 자동으로 Shape을 맞춰 연산해준다. 이를 브로드캐스팅(broadcasting)이라고 한다.\n",
    "\n",
    "채널의 가중치가 들어있는 weights 텐서를 `img_t`와 `batch_t`에 적용하려면, (3,) 인 weights 텐서를 (3, 1, 1)로 변환해야 한다.\n",
    "\n",
    "이 때, unsqueeze를 사용하여 차원을 추가하고, unsqueeze를 사용하여 차원을 맞춰준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "590a05d2946422fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:23:24.293898Z",
     "start_time": "2025-06-14T13:23:24.289955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1)\n",
    "unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2153f0b273edb567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:25:30.804837Z",
     "start_time": "2025-06-14T13:25:30.801816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_weights = img_t * unsqueezed_weights\n",
    "batch_weights = batch_t * unsqueezed_weights\n",
    "\n",
    "img_graph_weighted = img_weights.sum(-3)\n",
    "batch_graph_weighted = batch_weights.sum(-3)\n",
    "\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69005a0fb5824b50",
   "metadata": {},
   "source": [
    "위의 결과로 볼 수 있듯이, (3, 1, 1) 모양의 `unsqueezed_weights` 텐서가 배치 입력인 `batch_t`에 적용되었을 때, PyTorch는 자동으로 `unsqueezed_weights`를 (2, 3, 1, 1)로 변환하여 연산이 수행된 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36061ace49c9dabd",
   "metadata": {},
   "source": [
    "그런데 코드가 약간 복잡해졌다. `einsum`을 사용하면 차원별로 이름을 부여할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42fa33abe3bb9fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:28:59.201891Z",
     "start_time": "2025-06-14T13:28:59.194736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_graph_weighted_fancy = torch.einsum('...chw, c -> ...hw', img_t, weights)\n",
    "batch_graph_weighted_fancy = torch.einsum('...chw, c -> ...hw', batch_t, weights)\n",
    "batch_graph_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bdf9a93c247a0",
   "metadata": {},
   "source": [
    "그러나 이 방법도 많은 기호가 복잡하게 사용되고 있다. 보다 직관적인 방법으로 `named_tensor`를 사용할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71cdf2b8f492a36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:30:51.019581Z",
     "start_time": "2025-06-14T13:30:51.015475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channel',))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channel',])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4496dfb996e7dad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:33:12.195529Z",
     "start_time": "2025-06-14T13:33:12.192715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named:  torch.Size([3, 5, 5]) ('channel', 'rows', 'columns')\n",
      "batch named:  torch.Size([2, 3, 5, 5]) (None, 'channel', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "# 나중에 이름을 지정하려면 refine_names를 사용한다. 텐서 접근 시 생략 부호 ...를 사용하면 다른 차원은 건드리지 않는다.\n",
    "img_named = img_t.refine_names(..., 'channel', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channel', 'rows', 'columns')\n",
    "\n",
    "print(\"img named: \", img_named.shape, img_named.names)\n",
    "print(\"batch named: \", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c20f9b480755d",
   "metadata": {},
   "source": [
    "텐서 간의 연산은 각 차원의 크기가 같거나, 한쪽이 1이어서 다른 쪽으로 브로드캐스팅이 가능해야 한다.\n",
    "이때, 이름이 지정되어 있다면 PyTorch는 이름이 일치하는 차원끼리 알아서 확인해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d920f1a17322a8ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:35:48.154940Z",
     "start_time": "2025-06-14T13:35:48.151792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channel', 'rows', 'columns'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "# 'channel' 만 있던 weights_named가 img_named의 'channel' 차원과 일치하도록 확장된다.\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "733caf4b1ab60b10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:40:00.791626Z",
     "start_time": "2025-06-14T13:40:00.788814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum 처럼 차원 인수를 허용하는 함수들은 이름이 붙은 차원도 받아들인다.\n",
    "gray_named = (img_named * weights_aligned).sum('channel')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d9517248bcac4e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:38:48.327241Z",
     "start_time": "2025-06-14T13:38:48.322794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error when attempting to broadcast dims ['channel', 'rows', 'columns'] and dims ['channel']: dim 'columns' and dim 'channel' are at the same position from the right but do not match.\n"
     ]
    }
   ],
   "source": [
    "# 이름 있는 텐서를 사용한다고 차원을 자동으로 정렬해주지는 않는다.\n",
    "try:\n",
    "    gray_named = (img_named[..., :3] * weights_named).sum('channel')\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f16c7803004d470a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:40:04.461651Z",
     "start_time": "2025-06-14T13:40:04.458794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이름 있는 텐서를 사용하는 연산을 함수 밖에서도 사용하려면, 차원 이름에 None을 넣어 이름 없는 텐서를 만든다.\n",
    "gray_named = (img_named * weights_aligned).sum('channel')\n",
    "graph_plain = gray_named.rename(None)\n",
    "graph_plain.shape, graph_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7f71e0f02cd77",
   "metadata": {},
   "source": [
    "좀 더 부연설명하자면 이름 있는 텐서는 일부 연산에서만 동작하며,\n",
    "대부분의 PyTorch/외부 함수는 이름 없는 텐서만 지원하기 때문에 호환성을 위해 .rename(None)으로 이름을 제거하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8228112f3d93a0e0",
   "metadata": {},
   "source": [
    "## 텐서의 데이터 타입\n",
    "\n",
    "### 파이썬 표준 타입을 사용하지 않는 이유\n",
    "\n",
    "텐서는 다양한 데이터 타입을 가진다. 그러나 파이썬 타입은 사용하지 않는다. 그 이유는 다음과 같다.\n",
    "\n",
    "- 파이썬에서 숫자는 박싱(boxing)되어 객체로 다뤄진다. 따라서 수 백만 개 이상을 다뤄야 하는 딥러닝에서는 비효율적이다.\n",
    "- 파이썬의 리스트는 단순히 연속된 객체의 컬렉션이다. 이로 인해, 다음과 같은 비효율이 발생한다.\n",
    "  - 두 벡터의 내적, 합 등의 연산을 효율적으로 수행할 수 있는 연산이 지원되지 않는다.\n",
    "  - 리스트에 들어있는 데이터를 메모리에 최적화하여 배치할 방법이 없다.\n",
    "  - 리스트는 기본적으로 단일 차원만 지원하며, 중첩된 리스트로 다차원 배열을 구현할 수 있지만, 여전히 비효율적이다.\n",
    "- 파이썬 인터프리터는 최적화를 거친 컴파일된 코드보다 느리다.\n",
    "\n",
    "이러한 이유로 데이터과학 라이브러리는 NumPy에 의존하거나 PyTorch 텐처처럼 전용 데이터 구조를 만든 후 숫자 데이터 연산은 저수준 언어로 효율을 높이도록 구현한다.\n",
    "성능 최적화를 위해 텐서 내의 모든 객체는 같은 타입의 숫자여야 하고, PyTorch는 실행 중에 이런 숫자 타입을 계속 추적해야 한다.\n",
    "\n",
    "### 데이터 타입\n",
    "\n",
    "`tensor`, `zeros`, `ones` 등의 함수는 `dtype` 인수를 사용하여 텐서의 숫자 타입을 지정할 수 있다.\n",
    "\n",
    "`dtype` 인자는 표준 NumPy 타입과 거의 동일하다. `dtype` 인자에 지정할 수 있는 타입은 다음과 같다.\n",
    "\n",
    "| 타입                              | 설명           |\n",
    "|---------------------------------|--------------|\n",
    "| `torch.float32`, `torch.float`  | 32비트 부동소수점   |\n",
    "| `torch.float64`, `torch.double` | 64비트 부동소수점   |\n",
    "| `torch.float16`, `torch.half`   | 16비트 부동소수점   |\n",
    "| `torch.int8`                    | 8비트 정수       |\n",
    "| `torch.uint8`                   | 8비트 부호 없는 정수 |\n",
    "| `torch.int16`, `torch.short`    | 16비트 정수      |\n",
    "| `torch.int32`, `torch.int`      | 32비트 정수      |\n",
    "| `torch.int64`, `torch.long`      | 64비트 정수      |\n",
    "| `torch.bool`                    | 불리언 값       |\n",
    "\n",
    "### 가장 많이 사용되는 데이터 타입\n",
    "\n",
    "- 신경망 연산\n",
    "  - 신경망 연산은 대부분 32비트 부동소수점으로 수행된다.\n",
    "  - 배정밀도 64비트를 사용해도 모델 정확도가 크게 향상되지 않지만 더 많은 메모리를 사용하고 더 느리게 동작한다.\n",
    "  -16비트 반정밀도 부동소수점은 최신 GPU에서 대부분 지원되며, 정확도를 희생해서 신경망이 차지하는 공간을 줄일 수 있다.\n",
    "- 인덱스\n",
    "  - 텐서는 다른 텐서에 대한 인덱스로 사용할 수 있다.\n",
    "  - 이때, PyTorch는 인덱싱용 텐서를 64비트 정수 데이터 타입으로 간주한다.\n",
    "- bool\n",
    "  - `points > 1.0` 과 같은 predicate는 텐서 내 각각의 요소가 이 조건을 만족하는지 알려주는 bool 텐서를 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c33ef0df1cfbcfc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T02:50:32.982682Z",
     "start_time": "2025-06-15T02:50:32.976744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [ True,  True],\n",
       "        [ True, False]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bool 텐서 예시\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "mask = points > 1.0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af952cb08c892be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T04:14:43.471268Z",
     "start_time": "2025-06-15T04:14:43.466554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float64\n",
      "torch.float32 torch.int16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 텐서 타입 캐스팅\n",
    "# dtype 메소드를 이용한 캐스팅\n",
    "double_points = torch.zeros(10, 2).double()\n",
    "print(torch.zeros(10, 2).dtype, double_points.dtype)\n",
    "\n",
    "# to 메소드를 이용한 캐스팅\n",
    "short_points = torch.ones(10, 2).to(dtype=torch.short)\n",
    "print(torch.ones(10, 2).dtype, short_points.dtype)\n",
    "\n",
    "# 여러 타입을 가진 입력들이 연산을 거치며 서로 섞일 때 자동으로 제일 큰 타입으로 만들어진다.\n",
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.to(dtype=torch.short)\n",
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab7d96e001c8c",
   "metadata": {},
   "source": [
    "## 메모리 관점에서의 텐서\n",
    "\n",
    "- 텐서 내부의 값은 `torch.Storage` 인스턴스로 관리하며, 연속적인 메모리 블록에 저장된다.\n",
    "- 텐서 객체는 저장 공간을 추상화한 `Storage` 객체에 대한 뷰 (view) 역할을 하며, 오프셋을 사용해 공간의 임의 위치에 접근하거나 특정 차원의 크기를 단위로 해서 접근할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d782b6cca28a554f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T04:32:57.749005Z",
     "start_time": "2025-06-15T04:32:57.740270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/lb4d41pn56d4wnwsr9rxl20c0000gn/T/ipykernel_75000/3297796694.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  points.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "# 텐서가 세 개의 행과 두 개의 열을 가지고 있지만, 실제로는 크기가 6인 배열 공간이다.\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "182cfa87b3f3d51f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T04:34:41.172242Z",
     "start_time": "2025-06-15T04:34:41.168044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage()[2]  # 2번째 인덱스에 있는 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93986543fcd5ca27",
   "metadata": {},
   "source": [
    "## 텐서 메타데이터 - 사이즈, 오프셋, 스트라이드\n",
    "\n",
    "저장 공간을 인덱스로 접근할 때, 사이즈와 오프셋 그리고 스트라이드에 의존한다.\n",
    "\n",
    "- 사이즈(NumPy의 Shape와 같음): 차원별 요소의 수를 표시한 튜플\n",
    "- 오프셋: 저장 공간에 대한 오프셋은 색인 0의 요소가 저장된 위치를 나타낸다.\n",
    "- 스트라이드: 각 차원에서 다음 요소를 가리키고 싶을 때, 실제 저장 공간 상에서 몇 개의 요소를 건너뛰어야 하는지를 알려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb273b45ce329280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:42:01.849105Z",
     "start_time": "2025-06-15T05:42:01.844951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) (3, 1) 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x33_t = torch.tensor([[5.0, 7.0, 4.0], [1.0, 3.0, 2.0], [7.0, 3.0, 8.0]])\n",
    "print(x33_t.shape, x33_t.stride(), x33_t.storage_offset())\n",
    "\n",
    "x33_t[1][1] # tensor(3.) 이 나와야 한다. 0 + 3 * 1 + 1 * 1이 적용되었을 것이다.\n",
    "# 즉, 스토리지 오브젝트 상에서는 storage_offset() + stride[0] * 1 + stride[1] * 1 인덱스로 접근한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dae97e8b973dfa7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91b508aaf9f5ae92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:08:26.427768Z",
     "start_time": "2025-06-15T05:08:26.424424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3., 2.]), torch.Size([3]), (1,), 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x33_t[1], x33_t[1].shape, x33_t[1].stride(), x33_t[1].storage_offset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b279dc023abcb2",
   "metadata": {},
   "source": [
    "이러한 방식 덕분에 텐서의 전치(Transpose)나 일부만으로 더 작은 텐서를 만드는 데 필요한 연산을 효율적으로 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "id": "3263457c73da79ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:13:41.894555Z",
     "start_time": "2025-06-16T06:13:41.889320Z"
    }
   },
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points)\n",
    "\n",
    "points_t = points.t()  # 전치\n",
    "print(points_t)\n",
    "\n",
    "points.storage().data_ptr() == points_t.storage().data_ptr()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([[4., 5., 2.],\n",
      "        [1., 3., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d8f591805e0fd2fb",
   "metadata": {},
   "source": [
    "코드가 책과는 다른데, `storage()` 구현이 바뀌었는지 스토리지 인스턴스의 `id` 로 비교하면 안된다. `data_ptr()`를 사용하면 실제 메모리 주소를 알 수 있다.\n",
    "\n",
    "`data_ptr()` 의 공식 문서 설명: Returns the address of the first element of self tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686469c028412366",
   "metadata": {},
   "source": [
    "## 인접한 텐서\n",
    "\n",
    "가장 오른쪽 차원에서부터 증가되는 형태로 저장소에 값이 펼쳐진 텐서는 contiguous로 정의된다.\n",
    "\n",
    "인접한 텐서는 데이터 지역성 관점에서 CPU 메모리 접근 효율이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c30da36789b2411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T07:14:40.218661Z",
     "start_time": "2025-06-15T07:14:40.198524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1606686db5a225a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T07:14:51.977227Z",
     "start_time": "2025-06-15T07:14:51.973610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous() # 전치된 텐서는 인접하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cc44a8b786d4171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T07:18:14.006810Z",
     "start_time": "2025-06-15T07:18:13.995100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)  4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3, 1),\n",
       "  4.0\n",
       "  5.0\n",
       "  2.0\n",
       "  1.0\n",
       "  3.0\n",
       "  1.0\n",
       " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(points_t.stride(), points_t.storage())\n",
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont.stride(), points_t_cont.storage() # 새 저장 공간을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16c50d111a10dd",
   "metadata": {},
   "source": [
    "## 텐서를 GPU로 옮기기\n",
    "\n",
    "지금까지는 CPU 메모리에서 텐서를 다루었다. PyTorch는 GPU를 지원하며, GPU로 텐서를 옮길 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29136ec92738bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자에서 device 인자를 사용하여 GPU에 텐서를 생성할 수 있다.\n",
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e5171287e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또는, to 메소드를 사용하여 CPU 텐서를 GPU로 옮길 수 있다.\n",
    "points_gpu = points.to(device='cuda')\n",
    "# GPU가 둘 이상인 환경에서 특정 GPU에서 작업을 수행하게 만들 수 있다.\n",
    "points_gpu = points.to(device='cuda:0')  # 첫 번째 GPU로 옮김\n",
    "points_gpu = points.cuda(0) # 위와 동일한 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263aca28d345a3a6",
   "metadata": {},
   "source": [
    "## NumPy 호환\n",
    "\n",
    "PyTorch 텐서는 NumPy와 호환된다. Zero-copy 수준의 상호 변환이 가능한데, 이는 파이썬 버퍼 프로토콜 덕분이다.\n",
    "\n",
    "## 연습문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a205f7ea5f0018ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:19:55.464373Z",
     "start_time": "2025-06-15T08:19:55.457153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), 0, (1,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1. list(range(9))로부터 텐서를 만들어라. 사이즈, 오프셋, 스트라이드는 얼마일지도 계산해보자.\n",
    "# 1차원 배열을 텐서로 만들면 1차원 텐서가 된다.\n",
    "# 이로부터 사이즈는 Tensor([9]) 이고, 오프셋은 1이며 스트라이드는 (1,) 일 것이다.\n",
    "\n",
    "a = torch.tensor(list(range(9)))\n",
    "a.size(), a.storage_offset(), a.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cdd16b82a18a9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:20:35.451945Z",
     "start_time": "2025-06-15T08:20:35.448205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5129082192, 5128994896)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1-a. b = a.view(3, 3)으로 텐서를 만들어라. View의 역할은 무엇인가? a와 b 가 같은 공간을 가리키고 있는지 확인해보자.\n",
    "# View는 텐서를 다른 형태로 볼 수 있도록 해준다. 이 때, 원본 텐서의 저장소를 이용한다.\n",
    "b = a.view(3, 3)\n",
    "b_storage = b.storage()\n",
    "a_storage = a.storage()\n",
    "print(b)\n",
    "id(a_storage), id(b_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f3a61ecdad951ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:24:09.544652Z",
     "start_time": "2025-06-15T08:24:09.541011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5],\n",
      "        [7, 8]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), 4, (3, 1))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1-b. c = b[1:, 1:]로 텐서를 만들고 사이즈, 오프셋, 스트라이드는 얼마일지 계산해보라.\n",
    "# b 텐서에서 첫 번째 행 이후와 첫 번째 열 이후를 가리키므로, Tensor([[4, 5], [7, 8]])이 된다.\n",
    "# 사이즈는 torch.Size([2, 2]) 이고, 오프셋은 4, 스트라이드는 (3, 1) 이다.\n",
    "c = b[1:, 1:]\n",
    "print(c)\n",
    "c.size(), c.storage_offset(), c.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238d8a1",
   "metadata": {},
   "source": [
    "문제 2. 코사인이나 제곱근 같은 수학 연산을 하나 골라라.  \n",
    "동일한 역할을 하는 함수를 torch 라이브러리에서 찾을 수 있을까?\n",
    "\n",
    "->\n",
    "수학 연산과 관련된 문서는 https://docs.pytorch.org/docs/stable/torch.html#math-operations 이다.\n",
    "\n",
    "나는 표준편차를 계산하는 [`std`](https://docs.pytorch.org/docs/stable/generated/torch.std.html#torch.std) 함수를 골랐다. 이 연산은 Reduction Ops에 해당한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5928e4cd0a5ab595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:45:03.815960Z",
     "start_time": "2025-06-15T10:45:03.813197Z"
    }
   },
   "source": [
    "### 2-a. 텐서 a에 대해 해당 함수를 요소 단위로 실행해보라. 왜 오류가 발생할까?\n",
    "try:\n",
    "    a.std()\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# std는 floating point와 complex dtypes 만 지원한다."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: std and var only support floating point and complex dtypes\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:46:30.755177Z",
     "start_time": "2025-06-15T10:46:30.750489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### 2.b. 동작시키려면 어떤 연산이 필요할까?\n",
    "\n",
    "# a를 float로 변환한 후, std를 실행하면 된다.\n",
    "a_float = a.to(dtype=torch.float)\n",
    "a_float.std()"
   ],
   "id": "1f574ffa1f734ceb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7386)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T11:10:11.040398Z",
     "start_time": "2025-06-15T11:10:11.038510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### 2.c. 해당 연산을 추가 공간을 사용하지 않고 실행하는 함수가 있을까?\n",
    "# PyTorch에서 to()나 float() 등의 dtype 변환 연산은 항상 새로운 메모리를 사용하는 non-inplace 연산이다.\n",
    "# 따라서 추가 공간없이 표준 편차를 계산할 수 없다."
   ],
   "id": "51f7ceca699d92f9",
   "outputs": [],
   "execution_count": 73
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
